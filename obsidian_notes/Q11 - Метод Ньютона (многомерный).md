# Вопрос 11. Метод Ньютона минимизации функций многих переменных.

**Где читать в учебнике:**
*   **Стр. 116:** Раздел 3.6.4.
*   **Стр. 117:** Формулы (3.69), (3.70).

**Суть:** Это самый мощный метод безусловной оптимизации. Он использует информацию о кривизне поверхности (вторые производные), чтобы прыгнуть сразу в "центр ямы".

---

## 1. Идея метода (На пальцах)

> [!example] Параболическая чаша
> В методе градиентного спуска (Q10) мы аппроксимировали функцию **плоскостью** (касательной) и шли вниз.
> В методе Ньютона мы аппроксимируем функцию **параболоидом** (квадратичной чашей).
>
> 1.  Стоим в точке $x_k$.
> 2.  Строим вокруг себя "виртуальную чашу" (на основе первых и вторых производных).
> 3.  Прыгаем сразу в **дно** этой виртуальной чаши.
>
> Если реальная функция сама по себе квадратичная (как $x^2 + y^2$), метод находит ответ **за 1 шаг** из любой точки!

---

## 2. Математическая формулировка

Мы раскладываем функцию в ряд Тейлора до второго порядка:
$$ f(x) \approx f(x_k) + \langle f'(x_k), x - x_k \rangle + \frac{1}{2} \langle f''(x_k)(x - x_k), x - x_k \rangle $$

Чтобы найти минимум этой "чаши", нужно, чтобы градиент стал равен нулю. Это приводит к формуле шага.

> [!info] Алгоритм метода Ньютона
>
> **Шаг 1.** В точке $x^k$ вычисляем:
> *   Вектор градиента $\nabla f(x^k)$ (размер $n \times 1$).
> *   Матрицу Гессе $H(x^k) = f''(x^k)$ (размер $n \times n$, вторые производные).
>
> **Шаг 2.** Находим обратную матрицу Гессе: $[f''(x^k)]^{-1}$.
>
> **Шаг 3.** Делаем шаг:
> $$ x^{k+1} = x^k - [f''(x^k)]^{-1} \cdot f'(x^k) $$
>
> **Шаг 4.** Проверяем условие остановки (малость градиента): $\|\nabla f(x)\| < \varepsilon$.

---

## 3. Плюсы и минусы (Важно для экзамена)

| Плюсы (+) | Минусы (-) |
| :--- | :--- |
| **Скорость:** Сходится мгновенно (квадратичная скорость), если мы рядом с минимумом. | **Сложность:** Нужно считать $n^2$ вторых производных и обращать огромную матрицу на каждом шаге. |
| **Точность:** Очень высокая. | **Ненадежность:** Если начать далеко от минимума, метод может "улететь" в бесконечность. Работает только для выпуклых функций. |

*Примечание:* Чтобы метод не ломался, часто вводят регулировку шага $\alpha_k$, как в градиентном спуске: $x^{k+1} = x^k - \alpha_k [f'']^{-1} f'$.

---

## 4. Навигация
<< [[Q10 - Градиентный спуск]] | [[00_ПЛАН_ПОДГОТОВКИ]] | [[Q12 - Выпуклое программирование]] >>
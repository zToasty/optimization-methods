# Вопрос 6. Численные методы безусловной оптимизации. Метод перебора, Метод золотого сечения.

**Где читать в учебнике:**
*   **Стр. 33:** Метод перебора (равномерного поиска).
*   **Стр. 39:** Метод золотого сечения.

---

## 1. Введение: Что такое численные методы?

> [!info] Суть численных методов
> В отличие от классических методов (где мы берем производную и приравниваем к нулю), **численные методы** — это алгоритмы.
>
> Мы не получаем точную формулу ответа $x^* = \sqrt{2}$. Мы получаем **приближенное значение** с заданной точностью $\varepsilon$ (эпсилон) за конечное число шагов (итераций).
>
> Задача: Найти минимум функции $f(x)$ на отрезке $[a, b]$.

---

## 2. Метод перебора (равномерного поиска)

> [!info] Алгоритм метода перебора
> Это простейший пассивный метод поиска.
>
> **Суть:** Мы разбиваем отрезок $[a, b]$ на $n$ равных частей и вычисляем значение функции в каждой точке разбиения. Точка с наименьшим значением $f(x)$ считается приближенным решением.
>
> **Формулы:**
> 1.  Шаг сетки: $h = \frac{b-a}{n}$.
> 2.  Точки проб: $x_i = a + i \cdot h, \quad i = 0, \dots, n$.
> 3.  Результат: $x^* \approx x_k$, где $f(x_k) = \min \{f(x_0), \dots, f(x_n)\}$.
>
> **Точность:** Зависит от количества точек $n$. Чтобы достичь точности $\varepsilon$, нужно $n \ge \frac{b-a}{\varepsilon}$.

> [!example] Объяснение на пальцах
> Представь, что ты потерял ключи в темной комнате (на отрезке).
> Ты просто делаешь шаг 1 метр и смотришь под ноги. Потом еще шаг. И так до конца комнаты. Где было "глубже всего" (или где ключи блеснули) — там и ответ.
> *   **Плюс:** Работает для любых функций (даже кривых и рваных).
> *   **Минус:** Очень долго. Чтобы получить высокую точность, нужно сделать миллион вычислений.

---

## 3. Метод золотого сечения

> [!info] Условие применимости
> Метод работает только для **унимодальных** функций.
> *   **Унимодальная** — значит "одногорбая" (или "одноямная"). На отрезке есть только один минимум, без локальных волн.


**Где читать:** Стр. 41 (Алгоритм), Стр. 42 (Пример 2.6).

### 1. Подготовка и обозначения
В основе метода лежит константа "золотого сечения" $\tau$:
$$ \tau = \frac{\sqrt{5}-1}{2} \approx 0.618 $$
Тогда $1 - \tau \approx 0.382$.

### 2. Формальный алгоритм (со стр. 41)

> [!info] Алгоритм метода золотого сечения
> **Шаг 1 (Инициализация):**
> Задаем начальный интервал $[a, b]$ и точность $\varepsilon$.
> Находим две начальные пробные точки внутри интервала:
> $$ x_1 = a + (1-\tau)(b-a) \quad (\text{точка левее центра}) $$
> $$ x_2 = a + \tau(b-a) \quad (\text{точка правее центра}) $$
> Вычисляем значения функции: $f(x_1)$ и $f(x_2)$.
>
> **Шаг 2 (Сравнение и сужение):**
> Сравниваем значения функции в пробных точках.
>
> *   **Случай А:** Если $f(x_1) \le f(x_2)$ (минимум слева):
>     1.  Отбрасываем правую часть. Новый интервал: $[a, x_2]$. (То есть $b_{new} = x_2$).
>     2.  Точка $x_1$ становится "второй" точкой нового интервала ($x_2^{new} = x_1$). Значение $f$ в ней уже известно.
>     3.  Вычисляем новую точку $x_1^{new}$ по формуле $a + b - x_2^{new}$.
>
> *   **Случай Б:** Если $f(x_1) > f(x_2)$ (минимум справа):
>     1.  Отбрасываем левую часть. Новый интервал: $[x_1, b]$. (То есть $a_{new} = x_1$).
>     2.  Точка $x_2$ становится "первой" точкой нового интервала ($x_1^{new} = x_2$). Значение $f$ в ней уже известно.
>     3.  Вычисляем новую точку $x_2^{new}$ по формуле $a + b - x_1^{new}$.
>
> **Шаг 3 (Проверка точности):**
> Вычисляем текущую погрешность $\varepsilon_n = \frac{b-a}{2}$.
> Если $\varepsilon_n \le \varepsilon$, переходим к Шагу 4. Иначе — возвращаемся к Шагу 2.
>
> **Шаг 4 (Результат):**
> Полагаем приближенное решение серединой последнего отрезка:
> $$ x^* \approx \frac{a+b}{2} $$

---

### 3. Разбор примера 2.6 (стр. 42)

**Задача:**
Решить задачу $f(x) = x^4 + e^{-x} \to \min$ на отрезке $x \in [0; 1]$ с точностью $\varepsilon = 0.1$.

**Итерация 1:**
1.  **Отрезок:** $a=0, b=1$.
2.  **Вычисляем точки:**
    *   $x_1 = 0 + 0.382 \cdot (1-0) = 0.382$
    *   $x_2 = 0 + 0.618 \cdot (1-0) = 0.618$
3.  **Считаем функцию:**
    *   $f(x_1) = 0.382^4 + e^{-0.382} \approx 0.021 + 0.683 = 0.704$
    *   $f(x_2) = 0.618^4 + e^{-0.618} \approx 0.146 + 0.539 = 0.685$
4.  **Сравнение:**
    $f(x_1) > f(x_2)$ ($0.704 > 0.685$).
    Минимум находится **справа**. Мы должны отрезать левый кусок $[0, x_1]$.

**Переход к Итерации 2:**
*   **Новый отрезок:** $[0.382; 1]$. (То есть $a$ стало $0.382$, $b$ осталось $1$).
*   **Старая точка $x_2$** (которая была 0.618) попадает внутрь нового отрезка и становится новой $x_1$. Нам не нужно заново считать в ней функцию!
*   Находим только одну новую точку $x_2$.

**Таблица результатов (как в учебнике):**

| Итерация | $a$ (левый край) | $b$ (правый край) | $x_1$ | $x_2$ | $f(x_1)$ | $f(x_2)$ | Действие |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **1** | 0 | 1.000 | 0.382 | 0.618 | 0.704 | **0.685** | $f(x_1)>f(x_2)$, режем лево |
| **2** | 0.382 | 1.000 | 0.618 | 0.764 | **0.685** | 0.807 | $f(x_1)<f(x_2)$, режем право |
| **3** | 0.382 | 0.764 | 0.528 | 0.618 | 0.668 | 0.685 | $f(x_1)<f(x_2)$, режем право |
| ... | ... | ... | ... | ... | ... | ... | ... |

**Ответ:**
После достижения точности, середина отрезка $x^* \approx 0.55$, значение функции $f^* \approx 0.67$.

> [!example] Объяснение на пальцах (Магия экономии)
> Представь, что мы ищем клад на участке в 100 метров.
>
> 1.  **Обычный метод (дихотомия):** Делим пополам. Чтобы выбрать лучшую половину, нам нужно две точки рядом с центром. Мы копаем две ямы. На следующем шаге — снова две ямы.
>
> 2.  **Золотое сечение:** Мы копаем яму на отметке 62 метра и 38 метров.
>     *   Допустим, клад левее (в зоне 0-62). Мы выкидываем участок 62-100.
>     *   У нас остался участок 0-62. И в нем **уже есть выкопанная яма** на отметке 38! Она идеально подходит под пропорцию золотого сечения для нового участка.
>     *   Нам нужно копнуть **всего один раз** новую яму, чтобы продолжить поиск.
>
> Это самый эффективный метод среди тех, которые не используют производные.

---

## 4. Навигация
<< [[Q05 - Функция Лагранжа]] | [[00_ПЛАН_ПОДГОТОВКИ]] | [[Q07 - Методы с производными]] >>